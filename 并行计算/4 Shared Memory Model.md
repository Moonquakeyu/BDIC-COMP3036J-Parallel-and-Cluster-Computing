  

## 4-1 内存架构 (Memory Architectures)

### 1. 内存架构分类 (Memory Architecture Classification)

并行计算机主要依据两种分类方法：

- **弗林分类法** (Flynn's Taxonomy)
- **共享内存与分布式内存** (Shared vs. Distributed memory)

MIMD (多指令流多数据流) 系统可以根据内存访问方式进一步分为：

- **共享内存** (Shared memory)
- **分布式内存** (Distributed memory)
- **混合分布式-共享内存** (Hybrid distributed-shared memory)

### 2. 共享内存 (Shared Memory)

**共享内存特点** (Characteristics of Shared Memory)：

- 所有处理器可以访问**全局地址空间** (global address space)
- 多个处理器可以独立操作但共享相同的内存资源
- 当一个处理器更改内存位置中的值时，该更改对所有其他处理器可见（**隐式通信** implicit communication）

**共享内存分类**：

- **均匀内存访问** (Uniform Memory Access, UMA)
    
    - 所有处理器对内存的访问时间相同
    - 通常由**对称多处理器系统** (Symmetric Multiprocessor, SMP)代表
    - 所有处理器相同，具有相等的内存访问权限和访问时间
    - 有时称为**缓存一致性UMA** (Cache Coherent UMA, CC-UMA)
    
    想象一栋公寓楼：
    
    - 这栋楼里住着很多人（处理器）
    - 楼里有一个公共娱乐室（共享内存）
    - 每个住户从自己房间到娱乐室的距离**完全相同**
    - 所有人走到娱乐室的时间都一样快
    - 每个人都能平等使用娱乐室里的所有设施
    
    这就是UMA系统：所有处理器访问内存的速度一样快，没有谁比谁有优势。
    
- **非均匀内存访问** (Non-Uniform Memory Access, NUMA)
    
    - 通常通过物理链接两个或多个SMP系统构成
    - 一个SMP可以直接访问另一个SMP的内存
    - 并非所有处理器对所有内存都有相同的访问时间
    - 通过另一个SMP访问的内存位置需要更长时间
    
      
    
    度假村有多栋公寓楼（多个SMP系统）
    
    - 每栋楼都有自己的娱乐室（本地内存）
    - 住在1号楼的人去1号楼的娱乐室很快
    - 但如果1号楼的人想去2号楼的娱乐室，就需要走一段路，花更多时间
    - 虽然所有人都能使用所有楼的娱乐室，但去自己楼的娱乐室明显更方便
    
    这就是NUMA系统：处理器访问自己"附近"的内存很快，但访问"远处"的内存就会变慢。
    

  

**缓存一致性** (Cache Coherence)：

- 共享内存系统可能出现的问题是内存块的缓存可能过期
- 如果另一个处理器更改了我们缓存中的块，就可能发生这种情况
- **缓存一致性共享内存系统**有硬件确保这不可能发生
- 每当缓存中的块被更改时，缓存也会更新

**共享内存优势** (Advantages)：

- **全局地址空间**提供用户友好的内存编程视角
    - 无论连接到哪个处理器，内存地址没有区别
- 任务间的**数据共享**因内存靠近CPU而快速且统一

**共享内存劣势** (Disadvantages)：

- 内存与CPU之间的**可扩展性**不足
    - 添加更多CPU会几何级增加共享内存-CPU路径上的流量
- 程序员负责**同步结构**以确保"正确"访问全局内存
- 随着处理器数量增加，设计和生产共享内存机器变得越来越困难和昂贵

### 3. 分布式内存 (Distributed Memory)

**分布式内存特点** (Characteristics)：

- 处理器有各自的**本地内存** (local memory)
    - 这意味着没有全局地址空间！
- 对内存的更改对其他处理器不可见
    - 无需缓存一致性！
- 程序员必须定义**数据如何以及何时共享** (how and when data is shared)

**分布式内存优势** (Advantages)：

- 内存与处理器数量**可扩展** (scalable)
    - 访问内存的开销不会大幅增加
- 每个处理器对自己的内存有**快速访问** (rapid access)
    - 不需要复杂的缓存一致性硬件
- **成本效益** (cost effectiveness)：可以使用商品、现成的处理器和网络

**分布式内存劣势** (Disadvantages)：

- 程序员负责处理器间**数据通信**的许多细节
    - 任务间的同步也是程序员的责任
- 基于全局内存的**数据结构**在这种内存组织中可能难以使用
- 数据的**访问时间**将根据数据所在的内存而变化

### 4. 混合分布式-共享内存 (Hybrid Distributed-Shared Memory)

**混合内存特点** (Characteristics)：

- 世界上一些最大最快的计算机同时使用共享和分布式内存架构
- 内存通常在**缓存一致性SMP机器**或类似机器内共享
- 作为SMP一部分的处理器可以对该机器的内存使用全局寻址
- 共享内存组件可以是共享内存机器和/或**图形处理单元** (GPU)
- 分布式内存组件是多个共享内存/GPU机器的网络
    - 这些机器只知道自己的内存，不知道另一台机器上的内存
    - 需要**网络通信**将数据从一台机器移动到另一台机器

**混合内存优缺点** (Advantages and Disadvantages)：

- **可扩展性**更容易实现！
- 程序员负责在**更复杂的环境**中管理内存！

## 4-2 并行编程模型 (Parallel Programming Models)

### 1. 并行编程模型概述 (Overview)

**并行编程模型定义** (Definition)：

- 并行编程模型是**并行计算机架构的抽象** (abstraction of parallel computer architecture)
- 并行编程模型通常根据其**通用性和性能**进行评估
    - 通用性：不同问题对不同架构的表达能力
    - 性能：编译后的程序执行效率

**实现方式** (Implementations)：

- 可以从现有顺序编程语言内部调用的**库** (library)
- 作为现有编程语言的**扩展** (extension)
- 作为全新的编程语言

**常见并行编程模型** (Common Models)：

- 共享内存 (Shared Memory)（不含线程）
- 线程 (Threads)
- 分布式内存/消息传递 (Distributed Memory / Message Passing)
- 数据并行 (Data Parallel)
- 混合 (Hybrid)
- 单程序多数据 (Single Program Multiple Data, SPMD)
- 多程序多数据 (Multiple Program Multiple Data, MPMD)

### 2. 共享内存模型 (Shared Memory Model)

**共享内存模型特点** (Characteristics)：

- 任务共享**公共地址空间** (common address space)
- 任务**异步读写**内存
- 使用**锁/信号量** (locks/semaphores)等机制控制对共享内存的访问
    - 用于解决争用并防止**竞态条件和死锁** (race conditions and deadlocks)
- 这可能是最简单的并行编程模型

**共享内存模型优势** (Advantages)：

- 没有**数据所有权**的概念
- 这意味着**不需要专门通信数据**
- 所有进程都能看到并平等访问共享内存
- 程序开发通常可以简化

**共享内存模型劣势** (Disadvantages)：

- 管理数据位置可能很困难
- 保持数据局部性有优势
    - 它节省了多个进程使用相同数据时发生的内存访问、缓存刷新和总线流量
- 不幸的是，控制**数据局部性** (data locality)很难理解，可能超出普通用户的控制范围

**共享内存模型实现** (Implementations)：

- 在独立的共享内存机器上，本机操作系统、编译器和/或硬件提供对共享内存编程的支持
    - POSIX标准提供了使用共享内存的API，UNIX提供共享内存段
- 在分布式内存机器上，内存在机器网络上物理分布，但通过专门的硬件和软件变为全局
    - 可使用SHMEM库

### 3. 线程模型 (Threads Model)

**线程模型概述** (Overview)：

- 线程模型允许单个进程有**多个并发执行路径** (multiple concurrent execution paths)
    - 这些执行路径称为线程
- 进程通常被描述为"**重量级**"(heavy weight)
- 线程通常被描述为"**轻量级**"(light weight)

**进程定义** (Process Definition)：

- 进程是计算机正在执行的程序实例
    - 典型计算机上通常运行许多进程
- 进程负责管理程序的执行
- 包含：
    - 程序指令
    - 程序数据（堆栈、静态和堆）
    - 一些寄存器和程序计数器

**线程模型优势** (Advantages)：

- 每个线程有**本地数据**（自己的堆栈），但共享进程的资源
    - 程序代码只需存储一次！（更少开销）
    - 线程间共享内存的好处
- 线程通过共享内存通信
    - 这要求程序员考虑同步
- 线程可以频繁启动和完成，但主进程必须继续执行

1. **资源共享效率高**：
    - 每个线程有自己的本地数据（自己的堆栈），但共享进程的资源
    - 程序代码只需存储一次，减少了内存开销
    - 线程之间通过共享内存进行通信，速度快
2. **灵活性**：
    - 线程可以频繁启动和完成，但主进程可以继续执行
    - 可以根据需要动态调整线程数量
3. **简化编程**：
    - 相比进程间通信，线程间的数据共享更加简单直接

**线程模型实现** (Implementations)：

- 线程模型有许多实现
- 通常以两种方式实现：
    - 从并行源代码内部调用的**子例程库** (library of subroutines)
    - 嵌入在源代码中的**指令集** (set of directives)（例如OpenMP）
- 两个非常知名的实现：**POSIX线程**和**OpenMP**

**POSIX线程** (POSIX Threads)：

- 由IEEE POSIX 1003.1c标准（1995）规定。仅C语言。
- Unix/Linux操作系统的一部分
- 基于库
- 通常称为Pthreads
- 非常**显式的并行性**；需要程序员高度关注细节

**OpenMP**：

- 基于**编译器指令**；可以使用串行代码
- 由一组主要计算机硬件和软件供应商共同定义和认可
- 可移植/多平台，包括Unix和其他平台
- 有C/C++和Fortran实现
- 可以非常**容易和简单**使用 - 提供"增量并行"

### 4. 分布式内存/消息传递模型 (Distributed Memory/Message Passing Model)

**分布式内存/消息传递模型概述** (Overview)：

- 这种模型设计用于**无共享内存环境**的并行编程
- 任务/进程各自有自己的本地内存
    - 这可能分布在不同机器上
- 通过**显式发送和接收的消息**交换数据

**发送和接收** (Sending and Receiving)：

- 为了能够向另一个进程发送数据，它必须准备好接收
- 进程需要调用某种接收子程序
    - 然后它必须等待发送进程传输数据
- 发送和接收数据必须协调

**消息传递模型特点** (Characteristics)：

- 从编程角度看，消息传递实现通常包括子程序库
- 对这些子程序的调用嵌入在源代码中
- 程序员负责确定所有并行性

**消息传递模型实现** (Implementations)：

- 消息传递模型有很多实现
- 开发了一个标准接口，称为**消息传递接口** (Message Passing Interface, MPI)
    - 1994年首次发布
- MPI已成为消息传递的行业标准
- 当前版本是MPI-4.1，MPI-5.0正在开发中

**MPI特点** (MPI Features)：

- MPI专为C、C++和FORTRAN设计
- 但它也有其他语言的绑定：Java、MATLAB、OCaml、Python、R等
- MPI设计用于在许多不同架构上工作
- 我们程序中相同的代码会被调整为以最高效的方式运行
    - 如果代码在共享内存系统上运行，则会复制相关内存
    - 如果相同代码在分布式内存系统上运行，则相关数据将通过网络传输
    - 无论如何，我们编写相同的代码！

### 5. 数据并行模型 (Data Parallel Model)

**数据并行模型概述** (Overview)：

- 数据并行模型专注于对**数据集执行操作**
    - 这可能是数组或其他数据结构
- 所有任务都在同一数据结构上工作，但在不同分区/部分上
- 例如，对数组中的值求和

**数据并行模型在不同架构上的应用** (Application to Different Architectures)：

- 数据并行模型的应用取决于系统的架构
- 在共享内存架构上，所有任务可能通过全局内存访问数据结构
    - 然后每个任务在正确的分区上执行其操作
- 在分布式内存架构上，数据结构被分割并作为"块"存在于每个任务的本地内存中

**数据并行模型实现** (Implementations)：

- Coarray Fortran：用于SPMD并行编程的Fortran 95扩展
- Unified Parallel C (UPC)：用于SPMD并行编程的C扩展
- Global Arrays：在分布式数组数据结构上下文中提供共享内存风格的编程环境，带有C和Fortran 77绑定
- X10：IBM正在开发的基于PGAS的并行编程语言
- Chapel：由Cray领导的开源并行编程语言项目

### 6. 其他编程模型 (Other Programming Models)

**混合模型** (Hybrid Models)：

- 混合模型结合了前面描述的多个编程模型
- 目前，混合模型的常见例子是**消息传递模型** (MPI) 与**线程模型** (OpenMP) 的结合
- 这种混合模型很适合目前最流行的集群多核/众核机器硬件环境
- 另一个类似且越来越流行的混合模型例子是使用MPI与CPU-GPU（图形处理单元）编程结合

**单程序多数据** (SPMD)：

- SPMD实际上是一种"高级"编程模型，可以建立在前面提到的任何并行编程模型的组合之上
- **单程序**：所有任务同时执行其程序副本
    - 这个程序可以是线程、消息传递、数据并行或混合
- **多数据**：所有任务可能使用不同数据
- SPMD程序通常有必要的逻辑编程，允许不同任务分支或有条件地仅执行它们设计执行的程序部分

**多程序多数据** (MPMD)：

- 与SPMD一样，MPMD实际上是一种"高级"编程模型，可以建立在前面提到的任何并行编程模型的组合之上
- **多程序**：任务可能同时执行不同程序
    - 这些程序可以是线程、消息传递、数据并行或混合
- **多数据**：所有任务可能使用不同数据
- MPMD应用程序不如SPMD应用程序常见，但可能更适合某些类型的问题

---

这份详细的笔记涵盖了COMP3036J并行与集群计算课程中4-1和4-2部分的所有关键概念和专业术语，采用半中半英的格式呈现，以帮助您记忆专业术语，准备好应对期末MCQ考试。如果您需要对某些部分进行更详细的解释，或者有任何其他问题，请随时告诉我。祝您考试顺利！