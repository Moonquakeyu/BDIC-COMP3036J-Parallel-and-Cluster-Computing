# COMP3036J 并行与集群计算 (Parallel & Cluster Computing) 复习笔记

## 1. 并行计算基础 (Parallel Computing Fundamentals)

### 串行计算 (Serial Computing)

- 传统的软件编写方式，也称为**顺序计算**(sequential computation)
- 任务被分解为一系列指令
- 这些指令**一个接一个地执行**(executed one after another)
- 任何时刻只能执行一条指令
- 假设只有一个CPU
- 先执行t1，然后t2，然后t3，以此类推

### 并行执行 (Parallel Execution)

- 在并行计算中，我们**同时使用多个计算资源**(use multiple compute resources at the same time)解决单个问题
- 需要**多个处理器、核心或GPU**(multiple processors, cores, or GPUs)
- 任务被分解为可以并行解决的部分
- 每个部分进一步分解为一系列指令
- 来自每个部分的指令同时执行

### 并行计算资源 (Parallel Computing Resources)

**硬件计算资源**包括：

- 具有多个处理器的单台计算机（或具有多个核心的单个处理器）
- 具有专门计算资源的计算机，如**GPU、FPGA或协处理器**(GPUs, FPGAs, or Coprocessors)
- 通过网络连接的多台计算机
- 以上任意组合

**软件计算资源**包括：

- 并行编程模型：线程化、多处理(Threading, Multiprocessing)(如C中的pThreads、Java线程、Python多处理)
- 并行计算框架：**CUDA、OpenMP、MPI**(CUDA, OpenMP, MPI)

### 并行计算问题 (Parallel Computational Problems)

- 不是每个问题都可以并行解决
    - 例如：许多哈希函数等常见密集算法无法并行化
- 许多可以并行解决的问题可能不会看到好处
    - 过程中的其他部分可能存在瓶颈

**可并行算法通常具有以下特点**：

- 可以分解为离散的工作片段
- 这些片段可以同时执行
- 使用多个计算资源解决时耗时更少

**不适合并行化的问题类型**：

1. **固有顺序问题**(Inherently Sequential Problems)：数据依赖要求顺序执行
2. **高同步开销**(High Synchronization Overhead)：锁争用降低效率
3. **内存受限问题**(Memory-Bound Problems)：受内存访问速度限制，而非计算限制
4. **低计算复杂度**(Low Computational Complexity)：任务完成速度太快，并行无益
5. **高通信开销**(High Communication Overhead)：线程/进程间通信过多

### 为什么需要并行计算 (Why Parallel Computing)

创建可并行执行的算法很困难，我们这样做的原因包括：

- 节省时间（壁钟时间wall clock time）
- 在相同时间内解决更大的问题
- 同时解决多个任务
- 能够使用非本地资源
- 通过使用许多更便宜、功率较低的设备获得更多处理能力
- 解决对单个设备内存来说过大的问题

### 未来趋势 (The Future)

- 最近几十年的重点从更快的时钟速度转向CPU中的更多核心
- AI和其他密集型应用的日益使用导致GPU大规模发展
- 许多重要技术（如机器学习、云计算、大数据）都依赖于并行计算

## 2. 串行计算的局限性 (Limitations of Serial Computing)

### 串行计算的主要限制

- 传输速度限制(Transmission speeds)
- 微型化限制(Miniaturisation)
- 经济限制(Economy)
- 空间和热量限制(Space and heat)

### 传输速度限制 (Transmission Speed Limitations)

- 串行计算机的速度直接取决于数据通过硬件的速度
- 绝对限制是光速（30厘米/纳秒）
- 铜线的传输限制是9厘米/纳秒
- 要增加数据传输，我们必须：
    - 使组件靠得更近
    - 或发明新的更快的信息媒介

### 微型化限制 (Miniaturisation Limitations)

- 处理器中的晶体管越来越小
    - 许多当前一代处理器的晶体管尺寸以纳米(<15nm)计
- 这允许在每个芯片上放置越来越多的晶体管
- 最终，组件的小型化将达到极限
    - 我们不能小于单个原子

### 经济限制 (Economic Limitations)

- 公司制造处理器的程序非常复杂且昂贵
- 人们愿意为处理器支付的价格有限
    - 特别是如果你可以用一个更快的处理器的价格购买并使用10个更慢的处理器

### 空间和热量限制 (Space and Heat Limitations)

- 我们已经看到，通过将组件靠近可以提高传输速度
- 但是对于我们可以放置组件的小型化/接近程度有限制
- 另一个限制是组件密度越高，产生的热量就越多！
- 高性能CPU通常需要大型散热器和风扇，只是为了防止过热

## 3. 冯·诺依曼架构 (The Von Neumann Architecture)

### 冯·诺依曼架构概述

- 几乎所有现代处理器都基于相同的核心概念设计
- 这个概念被称为冯·诺依曼架构
- 由匈牙利数学家约翰·冯·诺依曼开发
- 它描述了能够执行存储在内存中的程序所必需的组件和操作

### 组件 (Components)

- 主要组件是**内存和CPU**(memory and a CPU)
- 内存用于存储数据，也存储程序的指令
    - 这要求指令可以用二进制格式表示
- CPU能够处理指令和数据并产生结果

### 连接 (Connections)

- 为了能够执行程序，CPU必须能够从内存加载指令
- 为了执行计算，CPU必须能够从内存读取数据
- 为了能够记住答案，CPU必须能够将数据写入内存

### 执行周期 (Execution Cycle)

- 冯·诺依曼架构的核心是CPU的操作
- 这必须设计为至少在两个阶段中运行
    - **取指令(Fetch)**：从内存中将指令加载到CPU中
    - **执行(Execute)**：执行我们加载的指令
- 当两者都完成时，将执行一条指令
- 然后CPU将执行下一条指令

## 4. 弗林分类法 (Flynn's Taxonomy)

### 弗林分类法概述

- 并行计算机最广泛使用的分类之一
- 弗林分类法沿着两个独立维度区分多处理器计算机架构
    - 指令(Instruction)
    - 数据(Data)
- 这些维度中的每一个只能有两种可能状态之一：单个(Single)或多个(Multiple)

### 分类矩阵 (Matrix)

弗林分类法定义了4种可能的分类：

|   |   |   |
|---|---|---|
||单数据(Single Data)|多数据(Multiple Data)|
|单指令(Single Instruction)|SISD|SIMD|
|多指令(Multiple Instruction)|MISD|MIMD|

### 单指令流单数据流 (SISD)

- 串行（非并行）计算机
- **单指令**：在任何一个时钟周期内，CPU仅处理一个指令流
- **单数据**：在任何一个时钟周期内，仅使用一个数据流作为输入
- 这种系统中的执行始终是确定性的
    - 相同的代码将始终产生相同的结果
- 这是最古老的，直到最近，最普遍的计算机架构形式
- 大多数计算机和笔记本电脑直到10-15年前

### 单指令流多数据流 (SIMD)

- 一种并行计算机
- **单指令**：所有处理单元在任何给定时钟周期执行相同的指令
- **多数据**：每个处理单元可以对不同的数据元素进行操作
- 同步（锁步）和确定性执行
- 这种机器通常有一个指令调度器、一个非常高带宽的内部网络和一个非常大的、容量非常小的指令单元阵列
- 最适合具有高度规律性的专业问题，如图像处理
- 两种变体：处理器阵列(Processor Arrays)和向量管道(Vector Pipelines)

### 多指令流单数据流 (MISD)

- 单个数据流被送入多个处理单元
- 每个处理单元通过独立的指令流独立地对数据进行操作
- 这类并行计算机的实际例子很少

### 多指令流多数据流 (MIMD)

- 当前最常见的并行计算机类型
- 大多数现代计算机属于这一类
- **多指令**：每个处理器可能正在执行不同的指令流
- **多数据**：每个处理器可能正在处理不同的数据流
- 执行可以是同步的或异步的，确定性的或非确定性的
- 大多数当前的超级计算机、网络并行计算机"网格"和多处理器SMP计算机以及许多PC都是MIMD

## 5. 重要术语 (Important Terminology)

### 处理器 (Processor)

- 可以执行计算的计算机组件
- 计算机的主处理器是中央处理单元CPU
- 计算屏幕布局的部分称为图形处理单元(GPU)

### 进程 (Process)

- 在大多数操作系统中的执行单元
- 正在执行的计算机程序的实例
- 进程包含程序的所有指令，以及任何数据
- 进程还记住下一步应该执行哪条指令

### 任务 (Task)

- 计算工作的逻辑离散部分
- 可以描述整个程序或程序的一部分
- 重要的是它描述了可以由处理器执行的指令

### 并行任务 (Parallel Task)

- 可以由多个处理器执行的任务
- 假设并行执行将返回与顺序执行相同的结果

### 串行/并行执行 (Serial/Parallel Execution)

**串行执行**：

- 按顺序执行程序，一次一条语句
- 这是在单处理器机器上发生的事情
- 几乎所有并行任务都将有必须串行执行的部分

**并行执行**：

- 由多个任务执行程序，每个任务能够在同一时刻执行相同或不同的语句

### 共享/分布式内存 (Shared/Distributed Memory)

**共享内存**：

- 硬件：一种计算机架构，所有处理器都可以直接访问公共物理内存
- 软件：一种模型，所有并行任务对内存都有相同的"图像"，可以直接寻址和访问相同的逻辑内存位置，无论物理内存实际在哪里

**分布式内存**：

- 硬件：基于网络的内存访问，用于不常见的物理内存
- 软件：任务在逻辑上只能"看到"本地机器内存，必须使用通信来访问其他执行任务的机器上的内存

### 通信 (Communication)

- 并行任务之间的数据交换
- 通常称为进程间通信(IPC)
- 可能涉及共享数据或通过网络传递消息

### 同步 (Synchronisation)

- 实时协调并行任务
    - 通常依赖于某种形式的通信
- 通常，这导致并行任务等待另一个任务到达特定点后再继续
    - 等待结果或资源是常见原因
- 同步通常涉及任务等待，增加壁钟时间

### 粒度 (Granularity)

- 在并行计算中，粒度是计算与通信比率的定性度量
- **粗粒度(Coarse)**：在通信事件之间进行相对大量的计算工作
- **细粒度(Fine)**：在通信事件之间进行相对少量的计算工作

### 观察到的加速比 (Observed Speedup)

- 观察到的加速比是转换为并行执行后执行速度提高的度量
- 比较串行执行速度和并行执行速度
- 并行程序性能最简单和最广泛使用的指标之一

### 并行开销 (Parallel Overhead)

- 并行开销是协调并行任务所需的时间量，而不是做有用工作
- 并行开销可能包括以下因素：
    - 任务启动时间(Task start-up time)
    - 同步(Synchronizations)
    - 数据通信(Data communications)
    - 任务终止时间(Task termination time)
    - 并行编译器、库、工具、操作系统等施加的软件开销

### 大规模并行 (Massively Parallel)

- 由"多"处理器组成的并行系统
    - "多"的含义一直在增加
    - 目前，"多"指数万个或更多处理器

### 可扩展性 (Scalability)

- 可扩展性是在添加更多处理器的情况下展示并行加速比例增加的能力
    - 这可以应用于硬件或软件
- 影响可扩展性的因素包括：
    - 应用程序算法
    - 硬件 - 特别是内存-CPU带宽和网络通信
    - 与并行开销相关的问题
- 重要的是要记住，可扩展性不是必然的
    - 如果它在两个处理器、两百个、两千个上工作，可能不会在50,000个上工作
    - 这可能是由于硬件、软件、问题本身等问题

---

希望这份半中半英文的详细笔记能帮助您准备即将到来的MCQ测验。我已经涵盖了3-1文件中的所有主要概念和专业术语，并使用了中英文对照的格式，便于您记忆这些术语。如果您需要对特定部分进行更详细的解释，请随时告诉我。祝您考试顺利！