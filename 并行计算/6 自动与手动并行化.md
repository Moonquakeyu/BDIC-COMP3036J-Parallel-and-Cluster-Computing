  

## 6-1 自动与手动并行化 (Automatic vs. Manual Parallelization)

### 1. 并行程序设计技术 (Parallel Program Design Techniques)

并行程序设计有多种技术，主要分为**自动并行化**和**手动并行化**。设计时需要考虑：

- 问题是否可并行化 (Is the problem parallelisable?)
- 热点和瓶颈在哪里 (What are the hotspots and bottlenecks?)
- 如何划分问题 (How is the problem partitioned?)
- 任务之间需要多少通信 (How much do the tasks need to communicate?)
- 如何同步程序 (How can the program be synchronised?)

### 2. 自动并行化 (Automatic Parallelization)

传统上，开发并行程序是一个手动过程，程序员负责识别和实现并行性。近年来，有多种工具可将串行程序转换为并行程序：

- 通常是**并行化编译器**或**预处理器** (parallelising compiler or pre-processor)
- 并行化编译器通常以两种方式工作：
    - **完全自动** (Fully automatic)
    - **程序员指导** (Programmer directed)

### 完全自动并行化 (Fully Automatic Parallelization)

- 编译器分析串行程序的源代码
- 识别并行机会 (opportunities for parallelism)
- 识别并行抑制因素 (inhibitors to parallelism)
- 分析并行是否会提高性能
- 循环通常是自动并行化的目标

### 程序员指导并行化 (Programmer Directed Parallelization)

- 使用"编译器指令"或编译器标志，程序员明确告诉编译器如何并行化代码
- 也可与某种程度的自动并行化结合使用
- 最常见的编译器生成的并行化是使用节点内共享内存和线程（如OpenMP）

### 自动并行化的问题 (Issues with Automatic Parallelization)

- 可能产生错误结果 (Wrong results)
- 性能可能实际下降 (Performance may degrade)
- 灵活性远低于手动并行化 (Less flexible)
- 仅限于代码的子集（主要是循环）
- 如果分析表明存在抑制因素或代码太复杂，可能不会并行化代码
- 许多自动并行化工具是为Fortran设计的

## 6-2 理解问题 (Understanding the Problem)

### 1. 问题分析 (Problem Analysis)

开发软件的第一步是理解要解决的问题，这也适用于开发并行软件。在尝试开发并行解决方案之前，需要确定问题是否可以并行化。

### 2. 可并行化问题示例 (Example of Parallelisable Problem)

**问题**：在大量照片中查找所有面孔，按相似性对面孔进行聚类。

这是一个容易并行化的问题：

- 每张照片可以独立分析以查找面孔
- 面孔相似性的成对比较可以独立完成
- 这实际上是两个独立的并行程序！
- 除了将第一个结果传递给第二个外，几乎不需要通信

### 3. 不可并行化问题示例 (Example of Non-Parallelisable Problem)

**问题**：计算斐波那契数列中的大数。

- 公式：f(k) = f(k-1) + f(k-2)
- 此问题不可并行化
- 序列中的每个数字都依赖于前两个值

### 4. 热点 (Hotspots)

**热点**是程序中完成实际工作的部分：

- 大多数科学和技术程序通常在几个地方完成大部分工作
- 分析器和性能分析工具可以帮助识别热点
- 专注于并行化热点，忽略CPU使用率较低的部分

### 5. 串行组件 (Serial Components)

- 并行代码的大部分实际上是串行的
- 很少的代码（以代码行计）是并行的
- 问题的串行组件无法并行化
- 但这些组件仍可以优化

### 6. 瓶颈 (Bottlenecks)

瓶颈是不成比例地慢或导致可并行化工作停止或延迟的区域：

- I/O通常会减慢程序速度
- 可能可以重构程序或使用不同算法来减少或消除不必要的慢区域
- 许多并行文件系统（如Lustre）可能有助于提高I/O性能

### 7. 抑制因素 (Inhibitors)

需要识别并行性的抑制因素：

- I/O通常被视为并行性的抑制因素
- 数据依赖也是并行性的抑制因素
    - 斐波那契数列就是一个例子

### 8. 其他算法 (Other Algorithms)

- 有些问题有多种解决算法
- 如果正在考虑的解决方案不可并行化，则应考虑替代方案
- 一些可能是可并行化的

## 6-3 问题分解 (Partitioning)

### 1. 分解基础 (Partitioning Basics)

设计并行程序的第一步是将问题分解为离散的"工作块"：

- 这些工作块可以分配给多个任务
- 这被称为**分解**或**划分** (decomposition or partitioning)

将计算工作分配给并行任务有两种基本方式：

- **域分解** (domain decomposition)
- **功能分解** (functional decomposition)

### 2. 域分解 (Domain Decomposition)

**域分解**基于分解问题数据：

- 每个并行任务处理部分数据
- 常见的分解方式包括：
    
    - **块分解** (Block): 连续块，数据访问主要是局部的，最小化通信
    - **循环分解** (Cyclic): 以循环方式分布。当某些计算比其他计算需要更多时间时很有用

### 3. 功能分解 (Functional Decomposition)

**功能分解**基于分解计算：

- 问题根据必须完成的工作进行分解
- 每个任务执行整体工作的一部分
- 适合可以分成不同任务的问题，例如：
    - 信号处理 (Signal Processing)
    - 气候建模 (Climate Modelling)

### 4. 混合分解 (Hybrid Decomposition)

结合这两种类型的问题分解既常见又自然。

## 6-4 通信 (Communications)

### 1. 通信需求 (Communication Needs)

任务之间通信的需求取决于你的问题：

1. **不需要通信**的例子：图像处理
    - 黑白图像的每个像素颜色反转操作
    - 数据可以轻松分配给多个独立工作的任务
    - 这类问题称为"令人尴尬的并行"(embarrassingly parallel)
2. **需要通信**的例子：3D热扩散
    - 模拟热量如何随时间在三维介质中传播
    - 任务需要知道具有相邻数据的任务计算的温度
    - 相邻数据的变化直接影响该任务的数据

### 2. 通信考虑因素 (Communication Considerations)

设计任务间通信时需要考虑的重要因素：

- **通信成本** (Cost of communication)
- **延迟与带宽** (Latency vs. bandwidth)
- **通信可见性** (Visibility of communications)
- **同步与异步** (Synchronous vs. asynchronous)
- **通信范围** (Scope of communications)

### 通信成本 (Cost of Communication)

- 任务间通信几乎总是意味着开销
- 可以用于计算的机器周期和资源被用于打包和传输数据
- 通信经常需要任务之间的某种同步，这可能导致任务"等待"而不是工作
- 竞争的通信流量可能饱和可用的网络带宽，进一步加剧性能问题

### 延迟与带宽 (Latency vs. Bandwidth)

- **延迟**：从A点向B点发送最小消息(1字节)所需的时间
- **带宽**：每单位时间可以通信的数据量
- 发送许多小消息会导致延迟主导通信开销
- 通常将小消息打包成更大的消息更高效，从而增加有效通信带宽

### 通信可见性 (Visibility of Communications)

- 在消息传递模型中，通信是显式的，通常对程序员可见并受其控制
- 在数据并行模型中，通信通常对程序员透明，特别是在分布式内存架构上
- 通信是否可见会影响你可以做的决策

### 同步与异步通信 (Synchronous vs. Asynchronous Communications)

- **同步通信**：要求共享数据的任务之间进行某种"握手"
    - 也称为阻塞通信，因为其他工作必须等待通信完成
- **异步通信**：允许任务独立传输数据
    - 也称为非阻塞通信，因为通信进行时可以做其他工作
    - 将计算与通信交错是使用异步通信的最大好处

### 通信范围 (Scope of Communications)

- 知道哪些任务必须相互通信在并行代码的设计阶段至关重要
- **点对点**：涉及两个任务，一个作为数据的发送者/生产者，另一个作为接收者/消费者
- **集体**：涉及两个以上任务之间的数据共享，这些任务通常被指定为公共组的成员

### 3. 通信效率 (Efficiency of Communication)

影响通信性能的因素：

- 使用哪种实现？一种MPI实现可能在给定硬件平台上比另一种更快
- 使用哪种通信操作？如前所述，异步通信操作可以提高整体程序性能
- 网络媒体 - 某些平台可能提供多个通信网络

## 6-5 同步 (Synchronisation)

### 1. 同步基础 (Synchronisation Basics)

管理工作序列和执行任务是大多数并行程序的关键设计考虑因素：

- 同步可能是程序性能（或性能不足）的重要因素
- 通常需要程序段的"串行化"

### 2. 同步类型 (Types of Synchronisation)

同步有不同类型：

- **屏障** (Barrier)
- **锁/信号量** (Lock / semaphore)
- **同步通信操作** (Synchronous communication operations)

### 屏障 (Barrier)

- 通常意味着所有任务都参与
- 每个任务执行其工作直到达到屏障，然后停止或"阻塞"
- 当最后一个任务到达屏障时，所有任务都同步
- 通常需要执行串行工作，之后任务可能自动释放继续工作

### 锁/信号量 (Lock / Semaphore)

- 可涉及任意数量的任务
- 通常用于序列化(保护)对全局数据或代码段的访问
- 只有一个任务可以使用(拥有)锁/信号量/标志
- 首先获得锁的任务"设置"它，然后可以安全(串行)访问受保护的数据或代码
- 其他任务可以尝试获取锁，但必须等待拥有锁的任务释放它

### 同步通信操作 (Synchronous communication operations)

- 只涉及执行通信操作的任务
- 当任务执行通信操作时，需要与参与通信的其他任务进行某种协调
- 例如，在任务执行发送操作之前，必须首先从接收任务收到确认，表明可以发送

### 3. 同步类型比较 (Comparison of Synchronization Types)

|   |   |   |
|---|---|---|
|类型|目的|示例使用|
|屏障 (Barrier)|强制所有线程等待，直到所有线程都到达某一点|OpenMP `#pragma omp barrier`|
|锁/信号量 (Lock/Semaphore)|控制对共享资源的访问|Pthread mutex, POSIX semaphore|
|同步通信 (Synchronous Communication)|确保数据在继续前正确传输|MPI_Ssend() 和 MPI_Recv()|

## 6-6 数据依赖 (Data Dependencies)

### 1. 数据依赖基础 (Data Dependencies Basics)

**依赖**存在于程序语句之间，当语句执行顺序影响程序结果时：

- **数据依赖**源于不同任务对存储中相同位置的多次使用
- 依赖对并行编程很重要，因为它们是并行性的主要抑制因素之一
- 简单来说：如果一段代码中的第二步需要用到第一步的结果，那么第二步就"依赖"于第一步，这就是数据依赖。

### 2. 循环载荷数据依赖 (Loop Carried Data Dependence)

```C
double array[500];
for (int i = 1; i < 500; i++) {
    array[i] = array[i-1] * 2.05;
}
```

- array[i-1]的值必须在计算array[i]的值之前计算
- 因此array[i]对array[i-1]表现出数据依赖
- 并行性受到抑制

这类数据依赖会导致并行化困难：

- 如果任务2有array[i]而任务1有array[i-1]，计算正确的array[i]值需要：
    - **分布式内存架构**：任务2必须在任务1完成计算后从任务1获取array[i-1]的值
    - **共享内存架构**：任务2必须在任务1更新后读取array[i-1]

### 3. 循环独立数据依赖 (Loop Independent Data Dependence)

```Plain
任务1        任务2
X = 2        X = 4
.            .
.            .
Y = X**2     Y = X**3
```

与前一个例子一样，并行性受到抑制。Y的值取决于：

- **分布式内存架构**：X的值是否或何时在任务之间通信
- **共享内存架构**：哪个任务最后存储X的值

### 4. 如何处理数据依赖 (How to Handle Data Dependencies)

虽然所有数据依赖在设计并行程序时都很重要，但循环承载的依赖特别重要，因为循环可能是并行化的最常见目标。

解决方案：

- **分布式内存架构**：在同步点通信所需数据
- **共享内存架构**：同步任务之间的读/写操作

## 6-7 负载平衡 (Load Balancing)

### 1. 负载平衡基础 (Load Balancing Basics)

**负载平衡**指的是在任务之间分配大致相等的工作量，使所有任务始终保持忙碌：

- 可以被视为任务空闲时间的最小化
- 负载平衡对并行程序的性能很重要
- 例如，如果所有任务都受到屏障同步点的约束，最慢的任务将决定整体性能

### 2. 如何实现负载平衡 (How to Achieve Load Balance)

有几种技术可以实现负载平衡：

- **平均分配工作** (Equally partitioning work)
- **动态工作分配** (Dynamic work assignment)

### 平均分配工作 (Partitioning Work)

- 对于每个任务执行类似工作的问题，可以在任务之间平均分配工作
- 对于每次迭代中完成的工作相似的循环迭代，平均分配迭代
- 这对于每个处理器具有类似性能的系统效果很好

然而，许多问题即使在数据均匀分布在相等机器上时也会导致负载不平衡：

- **稀疏数组**：一些任务有实际数据处理，而其他任务大多处理"零"
- **自适应网格方法**：一些任务可能需要细化其网格，而其他任务不需要
- **N体模拟**：粒子可能迁移到任务域，需要一些任务做更多工作

### 动态工作分配 (Dynamic Work Assignment)

一种解决方案是由程序在运行时确定分配：

- 当任务数量不可预测且无法提前分配时很有用
- 典型实现是使用共享工作队列
    - 列出所有要完成的任务
    - 工作线程从队列中提取任务执行，完成当前任务后从队列中提取另一个
    - 工作线程一直工作，直到工作队列为空

动态工作分配的不同方法：

- **调度器-任务池方法** (Scheduler-task pool approach)
- **工作共享** (Work sharing)
- **工作窃取** (Work stealing)

## 6-8 粒度 (Granularity)

### 1. 粒度基础 (Granularity Basics)

在并行计算中，任务的**粒度**是衡量该任务执行工作量的指标：

- 粒度通常测量为计算时间与通信时间的比率
    - 计算是花在工作上的时间
    - 通信是花在数据交换上的时间
- 并行性通常描述为细粒度或粗粒度

### 2. 细粒度并行 (Fine-Grained Parallelism)

**细粒度并行**特点：

- 通信事件之间完成相对较少的计算工作
- 低计算与通信比率
- 有利于负载平衡
- 通常与可分解为许多小任务的问题相关
- 可能导致大量进程和增加的通信和同步开销
- 最适合支持快速通信的架构
    

### 3. 粗粒度并行 (Coarse-Grained Parallelism)

**粗粒度并行**特点：

- 通信事件之间完成相对大量的计算工作
- 高计算与通信比率
- 负载平衡更困难
- 通常与可分解为大任务的问题相关
- 通信和同步开销较少
- 可以最好地利用通信时间较长的系统
    

### 4. 哪种最好 (Which is Best?)

最有效的粒度取决于算法和运行的硬件环境：

- 在大多数情况下，与执行速度相比，通信和同步相关的开销很高，因此粗粒度更有利
- 对于某些问题，程序员可以做出改变粒度的决策
- 两者都可能正常工作并产生正确结果，但一种可能比另一种更快

## 6-9 输入/输出 (I/O)

### 1. 输入/输出的挑战 (Challenges with I/O)

I/O操作通常被视为并行性的抑制因素：

- I/O操作所需时间比内存操作长数个数量级
- 并行I/O系统可能不成熟或不适用于所有平台
- 在所有任务都看到相同文件空间的环境中，写操作可能导致文件覆盖
- 读操作可能受到文件服务器同时处理多个读请求能力的影响
- 必须通过网络进行的I/O可能导致严重瓶颈，甚至使文件服务器崩溃

### 2. 操作时间 (Operation Times)

|   |   |   |
|---|---|---|
|类型|内存|时间(ns)|
|内部|寄存器|0.0|
|内部|L1缓存|0.5|
|内部|L2缓存|7.0|
|主内存|RAM|100.0|
|在线存储|SSD|1,000.0|
|在线存储|HDD|10,000.0|
|离线存储|磁带|10,000,000,000.0|

### 3. 解决方案 (Solutions)

**可用的并行文件系统**：

- GPFS：IBM通用并行文件系统（现称IBM Spectrum Scale）
- Lustre：用于Linux集群（Intel）
- HDFS：Hadoop分布式文件系统（Apache）
- PanFS：用于Linux集群的Panasas ActiveScale文件系统

**步骤**：

- 尽可能减少整体I/O
- 如果有并行文件系统，使用它
- 写入大块数据比小块数据通常效率高得多
- 少量大文件比多个小文件性能更好
- 将I/O限制在作业的特定串行部分，然后使用并行通信将数据分发给并行任务
- 跨任务聚合I/O操作，让部分任务执行I/O

## 6-10 并行编程的限制和成本 (Limits and Costs of Parallel Programming)

### 1. 阿姆达尔定律 (Amdahl's Law)

**阿姆达尔定律**指出，潜在的程序加速由可并行化的代码部分(P)定义：

```Plain
加速 = 1 / (1-P)
```

可并行化的代码越少，可能的加速越小。

### 2. 处理器数量 (Number of Processors)

引入执行并行部分工作的处理器数量，公式变为：

```Plain
加速 = 1 / (P/N + S)
```

其中：

- P是并行部分
- S是串行部分
- N是处理器数量
- 注意：P + S = 1

处理器数量与加速比的关系：

|         |        |        |        |
| ------- | ------ | ------ | ------ |
| 处理器数(N) | P=0.50 | P=0.90 | P=0.99 |
| 10      | 1.82   | 5.26   | 9.17   |
| 100     | 1.98   | 9.17   | 50.25  |
| 1000    | 1.99   | 9.91   | 90.99  |
| 10000   | 1.99   | 9.91   | 99.02  |

### 3. 阿姆达尔定律的后果 (Consequences of Amdahl's Law)

效率随着处理器数量的扩展变化告诉我们：

- 不可并行化的代码/工作量比可并行化的部分影响更大
- 可扩展性是一个问题，即使对于高度可并行化的解决方案
- 一些解决方案比其他解决方案扩展得更好，但没有一种扩展得特别好

### 4. 比较性能和问题规模 (Comparing Performance and Problem Size)

代码中串行和并行部分之间的百分比划分决定了可能的加速，但这可以与我们正在解决的问题大小有关：

- 增加问题大小（如网格维度增加）可以显著增加并行部分的比例
- 随着大小增加并行时间百分比的问题比具有固定并行时间百分比的问题更具可扩展性

## 6-11 其他考虑因素 (Other Considerations)

### 1. 复杂性 (Complexity)

一般来说，并行应用程序比相应的串行应用程序复杂得多：

- 不仅有多个同时执行的指令流，还有数据在它们之间流动
- 复杂性成本几乎在软件开发周期的每个方面都以程序员时间衡量
- 遵循"良好"的软件开发实践对处理并行应用程序至关重要
- 细节在并行编程中很重要，因为细节可能产生"乘法"效应

### 2. 可移植性 (Portability)

由于几个API的标准化，并行程序的可移植性问题不像过去那么严重：

- 与串行程序相关的所有常见可移植性问题适用于并行程序
- 即使存在几个API的标准，实现也会不同，有时需要代码修改
- 操作系统可能在代码可移植性问题中起关键作用
- 硬件架构特性高度可变，可能影响可移植性

### 3. 资源需求 (Resource Requirements)

并行编程的主要目的是减少执行墙钟时间，但为了实现这一点，需要更多CPU时间：

- 例如，在8个处理器上运行1小时的并行代码实际上使用了8小时的CPU时间
- 由于需要复制数据以及与并行支持库和子系统相关的开销，并行代码所需的内存量可能大于串行代码
- 对于短时间运行的并行程序，与类似的串行实现相比，性能实际上可能会下降

### 4. 可扩展性 (Scalability)

并行程序性能的可扩展性是多个相互关联因素的结果：

- 简单地添加更多机器很少是答案
- 算法可能有固有的可扩展性限制
- 在某一点上，添加更多资源会导致性能下降
- 大多数并行解决方案在某一点上表现出这种特性
- 硬件因素在可扩展性中起重要作用，例如：
    - SMP机器上的内存-CPU总线带宽
    - 通信网络带宽
    - 任何给定机器或机器集上可用的内存量
    - 处理器时钟速度
- 并行支持库和子系统软件可能会限制可扩展性，独立于您的应用程序

---

这份详细的笔记涵盖了COMP3036J第6章并行与集群计算的所有关键概念，采用了半中半英的格式，以帮助您记住专业术语，准备好应对期末MCQ考试。希望对您有所帮助！祝您考试顺利！